// ts-node/esm å®Ÿè¡Œï¼ˆingest ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼‰
import Parser from 'rss-parser';
import fs from 'node:fs/promises';
import { OpenAI } from 'openai';
import pLimit from 'p-limit';
import 'dotenv/config';

type FeedItem = {
  title?: string;
  link?: string;
  pubDate?: string;
  contentSnippet?: string;
  content?: string;
  creator?: string;
  categories?: string[];
};

export interface Article {
  title: string;
  link: string;
  pubDate: string;
  description?: string;
  creator?: string;
  categories?: string[];
  shortTitle: string;
  aiNote: string;
}

const FEED_URL =
  process.env.FEED_URL ??
  'https://news.google.com/rss/search?q=åºœä¸­å¸‚&hl=ja&gl=JP&ceid=JP%3Aja';
const NEWS_PATH = 'public/news.json';
const MAX_ARTICLES = 1000;

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const parser = new Parser<FeedItem>();
const limiter = pLimit(2); // åŒæ™‚ 2 ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§

async function summarize(item: FeedItem): Promise<{
  shortTitle: string;
  aiNote: string;
}> {
  const prompt = `
ã‚ãªãŸã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¦ç´„ã™ã‚‹AIã§ã™ã€‚

## å…¥åŠ›
TITLE: ${item.title}
DESCRIPTION: ${item.contentSnippet ?? ''}

## å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆJSONï¼‰
{
  "shortTitle": "15æ–‡å­—ä»¥å†…ã®çŸ­ã„ã‚¿ã‚¤ãƒˆãƒ«",
  "aiNote": "æœ€å¤§2è¡Œã®ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªæ‰€æ„Ÿï¼ˆå¥ç‚¹2ã¤ä»¥å†…ï¼‰"
}
`;

  try {
    const res = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      temperature: 0.4,
      messages: [
        { role: 'system', content: 'You output ONLY valid JSON.' },
        { role: 'user', content: prompt.trim() },
      ],
    });

    const text = res.choices[0].message.content?.trim() ?? '{}';
    const json = JSON.parse(text);
    return {
      shortTitle: json.shortTitle || item.title || '',
      aiNote: json.aiNote || '',
    };
  } catch (e) {
    console.error('âš ï¸  summary failed:', e);
    return { shortTitle: item.title ?? '', aiNote: '' };
  }
}

async function main() {
  const feed = await parser.parseURL(FEED_URL);
  const existing: Article[] = await fs
    .readFile(NEWS_PATH, 'utf8')
    .then((t) => JSON.parse(t))
    .catch(() => []);

  // é‡è¤‡åˆ¤å®šç”¨ã‚»ãƒƒãƒˆ
  const known = new Set(existing.map((a) => a.link));

  // æ–°ç€ã®ã¿
  const newcomers = feed.items.filter((i) => !known.has(i.link ?? '#'));

  const summarized = await Promise.all(
    newcomers.map((i) =>
      limiter(async () => {
        const sum = await summarize(i);
        return <Article>{
          title: i.title ?? '',
          link: i.link ?? '#',
          pubDate: i.pubDate ?? new Date().toUTCString(),
          description: i.contentSnippet ?? i.content ?? '',
          creator: i.creator,
          categories: i.categories,
          ...sum,
        };
      }),
    ),
  );

  // ãƒãƒ¼ã‚¸ & ã‚½ãƒ¼ãƒˆ & truncate
  const merged = [...summarized, ...existing].sort(
    (a, b) => new Date(b.pubDate).getTime() - new Date(a.pubDate).getTime(),
  ).slice(0, MAX_ARTICLES);

  await fs.writeFile(NEWS_PATH, JSON.stringify(merged, null, 2));
  console.log(`âœ… news.json updated: +${summarized.length} / total ${merged.length}`);
}

main().catch((e) => {
  console.error(e);
  process.exit(1);
});

await fs.writeFile(NEWS_PATH, JSON.stringify(merged, null, 2));  // æ—¢å­˜

// ğŸ‘‡ AIæƒ…å ±ä»˜ã data.json ã‚‚ä¿å­˜
const dataPath = 'public/data.json';
await fs.writeFile(dataPath, JSON.stringify(merged, null, 2));

console.log(`âœ… news.json updated: +${summarized.length} / total ${merged.length}`);
console.log(`âœ… data.json also updated`);
